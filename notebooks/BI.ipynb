{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from ppu.generator import GaussianBlobs, Circular, Moons, RingBlobs\n",
    "\n",
    "import gpytorch\n",
    "import random\n",
    "import torch\n",
    "import pyro\n",
    "import torch.nn.functional as F\n",
    "from dataset import get_dataset\n",
    "from utils import BI_LSE, accuracy, get_datasets, stable_logit_transform\n",
    "# from models import MLP\n",
    "from ppu.methods.mlp import MLP\n",
    "from copy import deepcopy\n",
    "from scipy.special import expit\n",
    "import seaborn as sns\n",
    "from sklearn.inspection._plot.decision_boundary import _check_boundary_response_method\n",
    "\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "import os\n",
    "os.makedirs('plots', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BI(xs, models):\n",
    "    preds = np.array([_check_boundary_response_method(m, 'auto')(xs) for m in models])\n",
    "    # preds might be probabilities\n",
    "    if len(preds.shape) == 3:\n",
    "        logits = stable_logit_transform(preds[:,:,1])\n",
    "    # or just logits\n",
    "    else:\n",
    "        logits = preds\n",
    "        \n",
    "    BIs = np.array([BI_LSE(zs, bound='lower') for zs in logits.T])\n",
    "    return BIs\n",
    "\n",
    "def get_models(clf, gen, reps, n_samples=200, **kwargs):\n",
    "    result = []\n",
    "    for rng in range(reps):\n",
    "        (X_train, y_train), (X_test, y_test) = get_dataset(rng, gen, n_samples=n_samples, **kwargs)\n",
    "        new_clf = deepcopy(clf)\n",
    "        new_clf.fit(X_train, y_train)\n",
    "        result.append(new_clf)\n",
    "    return result\n",
    "\n",
    "def nn_models(gen, n_models, n_samples=500, DE=False, extra_kwargs={}, **kwargs):\n",
    "    result = []\n",
    "    # if we want deep ensembles, we have to fix the dataset seed to get the same dataset\n",
    "    seeds = [0 for _ in range(n_models)] if DE else range(n_models)\n",
    "    \n",
    "    for rng in seeds:\n",
    "        (X_train, y_train), (X_test, y_test) = get_dataset(rng, gen, n_samples=n_samples, **extra_kwargs)\n",
    "        model = MLP(**kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "        result.append(model)\n",
    "    return result\n",
    "\n",
    "def BS_models(clf, gen, reps, n_samples=500, **kwargs):\n",
    "    result = []\n",
    "    seeds = range(reps)\n",
    "    (X_train, y_train), (X_test, y_test) = get_dataset(0, gen, n_samples=n_samples, **kwargs)\n",
    "    for _ in seeds:\n",
    "        bs_ind = random.choices(range(n_samples), k=n_samples)\n",
    "        bs_X = X_train[bs_ind]\n",
    "        bs_y = y_train[bs_ind]\n",
    "        model = deepcopy(clf)\n",
    "        model.fit(bs_X, bs_y)\n",
    "        result.append(model)\n",
    "    return result\n",
    "\n",
    "def BS_nn_models(gen, n_models, n_samples=500, DE=False, extra_kwargs={}, **kwargs):\n",
    "\n",
    "    # bootstrapping\n",
    "    result = []\n",
    "    seeds = range(n_models)\n",
    "    \n",
    "    (X_train, y_train), (X_test, y_test) = get_dataset(0, gen, n_samples=n_samples, **extra_kwargs)\n",
    "    for _ in seeds:\n",
    "        bs_ind = random.choices(range(n_samples), k=n_samples)\n",
    "        bs_X = X_train[bs_ind]\n",
    "        bs_y = y_train[bs_ind]\n",
    "        model = MLP(**kwargs)\n",
    "        model.fit(bs_X, bs_y)\n",
    "        result.append(model)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"5 Nearest Neighbors\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"XGBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"Neural Net\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=10),\n",
    "    GradientBoostingClassifier(n_estimators=10),\n",
    "    GaussianNB(),\n",
    "    MLP(hidden_channels=[30, 100, 50, 1], weight_decay=0., patience=20, frequency=2, device=\"mps\")\n",
    "]\n",
    "\n",
    "n_ticks = 100\n",
    "n_samples = 500  #train instances\n",
    "reps = 100 # train set sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppu.methods.bregman import *\n",
    "generator = {\n",
    "    'GaussianBlobs' : GaussianBlobs,\n",
    "    'Circular' : Circular,\n",
    "    'Moons' : Moons,\n",
    "    'RingBlobs' : RingBlobs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = 1\n",
    "gen = list(generator.values())[id]\n",
    "with threadpool_limits(limits=4):\n",
    "    models = {name: get_models(func, gen, reps=reps, n_samples=n_samples) for name, func in zip(names, classifiers)}\n",
    "# models['Neural Net'] = nn_models(gen, n_models=reps, n_samples=n_samples, hidden_channels=[30, 100, 50, 1], frequency=2, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppu.methods.bregman import *\n",
    "\n",
    "figure = diff_classifier(gen, n_samples, names, classifiers, models, rescale = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure.savefig('plots/ext_classifier_ds{}_{}_{}.png'.format(n_samples, list(generator.keys())[id], 'rescale') if False else 'plots/ext_classifier_ds{}_{}.png'.format(n_samples, list(generator.keys())[id]), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(1000, gen, n_samples=n_samples)\n",
    "offset = 1\n",
    "zoom_out = False # True or False means 0 or 1\n",
    "rows = 2 + zoom_out\n",
    "\n",
    "rescale = False\n",
    "\n",
    "gridspec_kw={'height_ratios': [1, 1]}\n",
    "cbar_kws = dict(use_gridspec=False, location=\"bottom\")\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "figure, axs = plt.subplots(rows, len(models) + offset, gridspec_kw=gridspec_kw, figsize=(27, 6+zoom_out*6))\n",
    "\n",
    "i = 0\n",
    "eps = 1\n",
    "n_ticks = 100\n",
    "\n",
    "ds = dataset\n",
    "(X_train, y_train), (X_test, y_test) = ds # X is the data point, y is the class label\n",
    "\n",
    "# the area we draw is a bit larger than the range of data points\n",
    "x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "# just plot the dataset first\n",
    "cm = plt.cm.RdBu # color map parameter\n",
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"]) # color for data points \n",
    "ax = axs[0][i] # position of subgraph\n",
    "ax.set_title(\"Data\") # subgraph title\n",
    "# Plot the training points\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "ax.set_xlim(x_min, x_max) # axis range\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "i += 1\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    ax = axs[0][i]\n",
    "    clf.fit(X_train, y_train) # clf is the method in classifiers\n",
    "    score = clf.score(X_test, y_test) # score of the result\n",
    "    x = np.linspace(x_min, x_max, n_ticks) # for the heatmap we need to creat the grid first, so n_ticks are the density of the grid nodes\n",
    "    y = np.linspace(y_min, y_max, n_ticks)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    X_grid = np.c_[xs.ravel(), ys.ravel()] # All the grid points\n",
    "\n",
    "    if name == \"Neural Net\":\n",
    "        response = clf.predict(X_grid)\n",
    "    else: # this if else is no needed\n",
    "        response = _check_boundary_response_method(clf, \"auto\")(X_grid) # the function returns the probability of points(inputs) belong to each class\n",
    "\n",
    "    if len(response.shape) == 1:\n",
    "        response = expit(response)\n",
    "    else:\n",
    "        response = response[:, 1] # since there's only 2 classes so 1 can represent the other(the prob sums up to 1)\n",
    "\n",
    "    display = DecisionBoundaryDisplay(\n",
    "        xx0=xs,\n",
    "        xx1=ys,\n",
    "        response=response.reshape(xs.shape),\n",
    "    ) # class to draw DecisionBoundary\n",
    "    display.plot(ax=ax, cmap=cm, alpha=0.8) # alpha controls the transparency of the filled contours\n",
    "\n",
    "    ax.set_xticks(()) # remove the ticks\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(name)\n",
    "    ax.text(\n",
    "        x_max - 0.3,\n",
    "        y_min + 0.3,\n",
    "        (\"%.2f\" % score).lstrip(\"0\"),\n",
    "        horizontalalignment=\"right\",\n",
    "    ) # score as text on the right bottom of the subgraph\n",
    "    i += 1\n",
    "# draw NN graph as NN is not in list names\n",
    "'''name = 'Neural Net'\n",
    "ax = axs[0][i]\n",
    "ax.set_title(name)\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "torch.manual_seed(1000)\n",
    "model = MLP(hidden_channels=[30, 100, 50, 1], weight_decay=0., patience=20, frequency=2)\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_test, y_test)\n",
    "x = np.linspace(x_min, x_max, n_ticks)\n",
    "y = np.linspace(y_min, y_max, n_ticks)\n",
    "xs, ys = np.meshgrid(x, y)\n",
    "X_grid = np.c_[xs.ravel(), ys.ravel()]\n",
    "\n",
    "response = model.predict(X_grid)\n",
    "response = expit(response)\n",
    "\n",
    "display = DecisionBoundaryDisplay(\n",
    "    xx0=xs,\n",
    "    xx1=ys,\n",
    "    response=response.reshape(xs.shape),\n",
    ")\n",
    "display.plot(ax=ax, cmap=cm, alpha=0.8)\n",
    "ax.set_title(name)\n",
    "ax.text(\n",
    "    x_max - 0.3,\n",
    "    y_min + 0.3,\n",
    "    (\"%.2f\" % score).lstrip(\"0\"),\n",
    "    horizontalalignment=\"right\",\n",
    ") # text on the graph'''\n",
    "\n",
    "i = 0\n",
    "if False: #zoom_out:\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "    ax = axs[1][i]\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "else:\n",
    "    ax = axs[1][i]\n",
    "    ax.axis('off') # turn off both x-axis and y-axis, including their labels and ticks\n",
    "\n",
    "i += 1\n",
    "\n",
    "x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "'''vmin = 1\n",
    "vmax = 0\n",
    "for name in models.keys():\n",
    "    ax = axs[1][i]\n",
    "    x = np.linspace(x_min, x_max, n_ticks)\n",
    "    y = np.linspace(y_min, y_max, n_ticks)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    X_grid = np.c_[xs.ravel(), ys.ravel()] # same as above\n",
    "    response = get_BI(X_grid, models[name])\n",
    "    if min(response) < vmin:\n",
    "        vmin = min(response)\n",
    "    if max(response) > vmax:\n",
    "        vmax = max(response)'''\n",
    "\n",
    "# iterate over classifiers\n",
    "for name in models.keys():\n",
    "    ax = axs[1][i]\n",
    "    x = np.linspace(x_min, x_max, n_ticks)\n",
    "    y = np.linspace(y_min, y_max, n_ticks)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    X_grid = np.c_[xs.ravel(), ys.ravel()] # same as above\n",
    "    response = get_BI(X_grid, models[name])\n",
    "    if rescale:\n",
    "        vmin = min(response)\n",
    "        vmax = max(response)\n",
    "        response = (response-vmin) / (vmax-vmin)\n",
    "    response = response.reshape(xs.shape)\n",
    "\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response, ax=ax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "i = 0\n",
    "if zoom_out:\n",
    "    eps = 5\n",
    "    x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "    y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "    ax = axs[2][i]\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name in models.keys():\n",
    "        ax = axs[i]\n",
    "        x = np.linspace(x_min, x_max, n_ticks)\n",
    "        y = np.linspace(y_min, y_max, n_ticks)\n",
    "        xs, ys = np.meshgrid(x, y)\n",
    "        X_grid = np.c_[xs.ravel(), ys.ravel()]\n",
    "        response = get_BI(X_grid, models[name])\n",
    "        response = response.reshape(xs.shape)\n",
    "\n",
    "        with np.errstate(all='ignore'):\n",
    "            sns.heatmap(response, ax=ax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        i += 1\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.subplots_adjust(#left=0.1,\n",
    "                    bottom=.17,\n",
    "                    #right=0.9,\n",
    "                    top=.9,\n",
    "                    wspace=0.,\n",
    "                    hspace=0.)\n",
    "plt.savefig('plots/ext_classifier_ds{}_{}_{}.png'.format(n_samples, list(generator.keys())[id], 'rescale') if rescale else 'plots/ext_classifier_ds{}_{}.png'.format(n_samples, list(generator.keys())[id]), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in models['Gaussian Process']:\n",
    "    print(_check_boundary_response_method(clf, 'auto')([[2.4, 2.67]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_models = BS_nn_models(gen, n_models=64, n_samples=n_samples, hidden_channels=[30, 100, 50, 1], frequency=2, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train deep ensemble\n",
    "de_models = nn_models(gen, n_models=64, n_samples=n_samples, hidden_channels=[30, 100, 50, 1], frequency=2, patience=25, DE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 6\n",
    "dataset = get_dataset(1000, gen, n_samples=n_samples)\n",
    "zoom_out = False\n",
    "\n",
    "cbar_kws = dict(use_gridspec=False, location=\"bottom\")\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "figure, axs = plt.subplots(1, 4, figsize=(12, 3.5))\n",
    "eps = 1\n",
    "n_ticks = 100\n",
    "\n",
    "ds = dataset\n",
    "(X_train, y_train), (X_test, y_test) = ds\n",
    "\n",
    "x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "# just plot the dataset first\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"])\n",
    "ax = axs[0]\n",
    "ax.set_title(\"Data\")\n",
    "# Plot the training points\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "name = 'Neural Net'\n",
    "x = np.linspace(x_min, x_max, n_ticks)\n",
    "y = np.linspace(y_min, y_max, n_ticks)\n",
    "xs, ys = np.meshgrid(x, y)\n",
    "X_grid = np.c_[xs.ravel(), ys.ravel()]\n",
    "\n",
    "# Real BI (approx over training set samples\n",
    "response = get_BI(X_grid, models[name])\n",
    "response = response.reshape(xs.shape)\n",
    "\n",
    "ax = axs[1]\n",
    "with np.errstate(all='ignore'):\n",
    "    sns.heatmap(response, ax=ax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "ax.set_title('Real BI')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "# BI bootstrap\n",
    "response = get_BI(X_grid, bs_models)\n",
    "response = response.reshape(xs.shape)\n",
    "\n",
    "ax = axs[2]\n",
    "with np.errstate(all='ignore'):\n",
    "    sns.heatmap(response, ax=ax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "ax.set_title('Bootstrap BI')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "# BI deep ensembles\n",
    "response = get_BI(X_grid, de_models)\n",
    "response = response.reshape(xs.shape)\n",
    "\n",
    "ax = axs[3]\n",
    "with np.errstate(all='ignore'):\n",
    "    sns.heatmap(response, ax=ax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "ax.set_title('Deep Ens. BI')\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.subplots_adjust(#left=0.1,\n",
    "                    bottom=.24,\n",
    "                    #right=0.9,\n",
    "                    top=.9,\n",
    "                    wspace=0.,\n",
    "                    hspace=0.)\n",
    "plt.savefig('plots/BI_approx_ds{}_{}.png'.format(n_samples, list(generator.keys())[id]), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selected = [\n",
    "    \"5 Nearest Neighbors\",\n",
    "    \"Gaussian Process\",\n",
    "    \"XGBoost\",\n",
    "    \"Neural Net\"\n",
    "]\n",
    "selected_models = {k: models[k] for k in model_selected if k in models}\n",
    "selected_models.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(1000, gen, n_samples=n_samples)\n",
    "gridspec_kw={'height_ratios': [1, 1]}\n",
    "cbar_kws = dict(use_gridspec=False, location=\"bottom\")\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "figure, axs = plt.subplots(2, 5, figsize=(15, 7))\n",
    "\n",
    "\n",
    "i = 0\n",
    "eps = 1\n",
    "n_ticks = 100\n",
    "\n",
    "ds = dataset\n",
    "(X_train, y_train), (X_test, y_test) = ds # X is the data point, y is the class label\n",
    "\n",
    "# the area we draw is a bit larger than the range of data points\n",
    "x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "# just plot the dataset first\n",
    "cm = plt.cm.RdBu # color map parameter\n",
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"]) # color for data points \n",
    "ax = axs[0][i] # position of subgraph\n",
    "ax.set_title(\"Data\") # subgraph title\n",
    "# Plot the training points\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "ax.set_xlim(x_min, x_max) # axis range\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "i += 1\n",
    "\n",
    "for name in selected_models.keys():\n",
    "    ax = axs[0][i]\n",
    "    ax.set_title(name)\n",
    "    x = np.linspace(x_min, x_max, n_ticks)\n",
    "    y = np.linspace(y_min, y_max, n_ticks)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    X_grid = np.c_[xs.ravel(), ys.ravel()] # same as above\n",
    "    response = get_BI(X_grid, models[name])\n",
    "    if rescale:\n",
    "        vmin = min(response)\n",
    "        vmax = max(response)\n",
    "        response = (response-vmin) / (vmax-vmin)\n",
    "    response = response.reshape(xs.shape)\n",
    "\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response, ax=ax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "\n",
    "i = 0\n",
    "ax = axs[1][i]\n",
    "ax.axis('off')\n",
    "i += 1\n",
    "\n",
    "for name in selected_models.keys():\n",
    "    x = np.linspace(x_min, x_max, n_ticks)\n",
    "    y = np.linspace(y_min, y_max, n_ticks)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    X_grid = np.c_[xs.ravel(), ys.ravel()]\n",
    "\n",
    "    if name == 'Neural Net':\n",
    "        response = get_BI(X_grid, BS_nn_models(gen, n_models=64, n_samples=n_samples, hidden_channels=[30, 100, 50, 1], frequency=2, patience=25))\n",
    "    else:\n",
    "        with threadpool_limits(limits=1):\n",
    "            response = get_BI(X_grid, BS_models(dict(zip(names, classifiers))[name], gen, reps=64, n_samples=n_samples))\n",
    "    response = response.reshape(xs.shape)\n",
    "    ax = axs[1][i]\n",
    "\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response, ax=ax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "plt.subplots_adjust(#left=0.1,\n",
    "                    bottom=.2,\n",
    "                    #right=0.9,\n",
    "                    top=.9,\n",
    "                    wspace=0.1,\n",
    "                    hspace=0.3)\n",
    "plt.savefig('plots/BI_bBI_ds{}_{}.png'.format(n_samples, list(generator.keys())[id]), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset(1000, gen, n_samples=n_samples)\n",
    "gridspec_kw={'height_ratios': [1, 1]}\n",
    "cbar_kws = dict(use_gridspec=False, location=\"bottom\")\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "figure, axs = plt.subplots(2, 5, figsize=(15, 7))\n",
    "\n",
    "\n",
    "i = 0\n",
    "eps = 1\n",
    "n_ticks = 100\n",
    "\n",
    "ds = dataset\n",
    "(X_train, y_train), (X_test, y_test) = ds # X is the data point, y is the class label\n",
    "\n",
    "# the area we draw is a bit larger than the range of data points\n",
    "x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "# just plot the dataset first\n",
    "cm = plt.cm.RdBu # color map parameter\n",
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"]) # color for data points \n",
    "ax = axs[0][i] # position of subgraph\n",
    "ax.set_title(\"Data\") # subgraph title\n",
    "# Plot the training points\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "ax.set_xlim(x_min, x_max) # axis range\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "i += 1\n",
    "\n",
    "ax = axs[1][0]\n",
    "ax.axis('off')\n",
    "\n",
    "for name in selected_models.keys():\n",
    "    \n",
    "    \n",
    "    x = np.linspace(x_min, x_max, n_ticks)\n",
    "    y = np.linspace(y_min, y_max, n_ticks)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    X_grid = np.c_[xs.ravel(), ys.ravel()]\n",
    "    response1 = get_BI(X_grid, models[name])\n",
    "    vmin = min(response1)\n",
    "    vmax = max(response1)\n",
    "    response1 = response1.reshape(xs.shape)\n",
    "\n",
    "    \n",
    "    if name == 'Neural Net':\n",
    "        response2 = get_BI(X_grid, BS_nn_models(gen, n_models=64, n_samples=n_samples, hidden_channels=[30, 100, 50, 1], frequency=2, patience=25))\n",
    "    else:\n",
    "        with  threadpool_limits(limits=1):\n",
    "            response2 = get_BI(X_grid, BS_models(dict(zip(names, classifiers))[name], gen, reps=64, n_samples=n_samples))\n",
    "    vmin = min(vmin, min(response2))\n",
    "    vmax = max(vmax, max(response2))\n",
    "    response2 = response2.reshape(xs.shape)\n",
    "\n",
    "    ax = axs[0][i]\n",
    "    ax.set_title(name)\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response1, ax=ax, vmin=vmin, vmax=vmax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "\n",
    "    ax = axs[1][i]\n",
    "\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response2, ax=ax, vmin=vmin, vmax=vmax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "    i += 1\n",
    "\n",
    "\n",
    "plt.subplots_adjust(#left=0.1,\n",
    "                    bottom=.2,\n",
    "                    #right=0.9,\n",
    "                    top=.9,\n",
    "                    wspace=0.1,\n",
    "                    hspace=0.3)\n",
    "plt.savefig('plots/BI_bBI_ds{}_{}.png'.format(n_samples, list(generator.keys())[id]), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "different class_sep\n",
    "'''\n",
    "\n",
    "name = 'Neural Net'\n",
    "if name != 'Neural Net':\n",
    "    func = dict(zip(names, classifiers))[name]\n",
    "name_gen = 'Circular'\n",
    "gen = generator[name_gen]\n",
    "gridspec_kw={'height_ratios': [1, 1]}\n",
    "cbar_kws = dict(use_gridspec=False, location=\"bottom\")\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "figure, axs = plt.subplots(3, 5, figsize=(15, 10.5))\n",
    "reps = 64\n",
    "\n",
    "i = 0\n",
    "eps = 1\n",
    "n_ticks = 100\n",
    "\n",
    "\n",
    "sep = [0.5 * i for i in range(5)]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    dataset = get_dataset(1000, gen, n_samples=n_samples, class_sep=sep[i])\n",
    "    ds = dataset\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = ds # X is the data point, y is the class label\n",
    "\n",
    "    if name == \"Neural Net\":\n",
    "        sep_model = nn_models(gen, n_models=reps, n_samples=n_samples, extra_kwargs={'class_sep':sep[i]}, hidden_channels=[30, 100, 50, 1], frequency=2, patience=20)\n",
    "    else:\n",
    "        with threadpool_limits(limits=1):\n",
    "            sep_model = get_models(func, gen, reps=reps, n_samples=n_samples, class_sep=sep[i])\n",
    "\n",
    "    # the area we draw is a bit larger than the range of data points\n",
    "    x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "    y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "    cm = plt.cm.RdBu # color map parameter\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"]) # color for data points \n",
    "    ax = axs[0][i] # position of subgraph\n",
    "    ax.set_title('{} sep={}'.format(name_gen, sep[i])) # subgraph title\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    ax.set_xlim(x_min, x_max) # axis range\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    \n",
    "    x = np.linspace(x_min, x_max, n_ticks)\n",
    "    y = np.linspace(y_min, y_max, n_ticks)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    X_grid = np.c_[xs.ravel(), ys.ravel()]\n",
    "    response1 = get_BI(X_grid, sep_model)\n",
    "    vmin = min(response1)\n",
    "    vmax = max(response1)\n",
    "    response1 = response1.reshape(xs.shape)\n",
    "\n",
    "    \n",
    "    if name == 'Neural Net':\n",
    "        response2 = get_BI(X_grid, BS_nn_models(gen, n_models=reps, n_samples=n_samples, extra_kwargs={'class_sep':sep[i]}, hidden_channels=[30, 100, 50, 1], frequency=2, patience=25))\n",
    "    else:\n",
    "        with threadpool_limits(limits=1):\n",
    "            response2 = get_BI(X_grid, BS_models(func, gen, reps=reps, n_samples=n_samples), class_sep=sep[i])\n",
    "    vmin = min(vmin, min(response2))\n",
    "    vmax = max(vmax, max(response2))\n",
    "    response2 = response2.reshape(xs.shape)\n",
    "\n",
    "    ax = axs[1][i]\n",
    "    #ax.set_title()\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response1, ax=ax, vmin=vmin, vmax=vmax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "\n",
    "    ax = axs[2][i]\n",
    "\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response2, ax=ax, vmin=vmin, vmax=vmax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "    i += 1\n",
    "\n",
    "\n",
    "plt.subplots_adjust(#left=0.1,\n",
    "                    bottom=.2,\n",
    "                    #right=0.9,\n",
    "                    top=.9,\n",
    "                    wspace=0.1,\n",
    "                    hspace=0.5)\n",
    "plt.savefig('plots/BI_bBI_classsep_ds{}_{}_{}.png'.format(n_samples, gen, name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "different variance\n",
    "'''\n",
    "\n",
    "name = 'Neural Net'\n",
    "if name != 'Neural Net':\n",
    "    func = dict(zip(names, classifiers))[name]\n",
    "name_gen = 'Circular'\n",
    "gen = generator[name_gen]\n",
    "gridspec_kw={'height_ratios': [1, 1]}\n",
    "cbar_kws = dict(use_gridspec=False, location=\"bottom\")\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "figure, axs = plt.subplots(3, 5, figsize=(15, 10.5))\n",
    "reps = 64\n",
    "\n",
    "i = 0\n",
    "eps = 1\n",
    "n_ticks = 100\n",
    "\n",
    "\n",
    "v = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    dataset = get_dataset(1000, gen, n_samples=n_samples, scale=(v[i], v[i]), class_sep=1.7)\n",
    "    ds = dataset\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = ds # X is the data point, y is the class label\n",
    "\n",
    "    if name == \"Neural Net\":\n",
    "        sep_model = nn_models(gen, n_models=reps, n_samples=n_samples, extra_kwargs={'class_sep':1.7, 'scale':(v[i], v[i])}, hidden_channels=[30, 100, 50, 1], frequency=2, patience=20)\n",
    "    else:\n",
    "        sep_model = get_models(func, gen, reps=reps, n_samples=n_samples, scale=(v[i], v[i]), class_sep=1.7)\n",
    "\n",
    "    # the area we draw is a bit larger than the range of data points\n",
    "    x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "    y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "    cm = plt.cm.RdBu # color map parameter\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"]) # color for data points \n",
    "    ax = axs[0][i] # position of subgraph\n",
    "    ax.set_title('{} Var={}'.format(name_gen, v[i])) # subgraph title\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "    ax.set_xlim(x_min, x_max) # axis range\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    \n",
    "    x = np.linspace(x_min, x_max, n_ticks)\n",
    "    y = np.linspace(y_min, y_max, n_ticks)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    X_grid = np.c_[xs.ravel(), ys.ravel()]\n",
    "    response1 = get_BI(X_grid, sep_model)\n",
    "    vmin = min(response1)\n",
    "    vmax = max(response1)\n",
    "    response1 = response1.reshape(xs.shape)\n",
    "\n",
    "    \n",
    "    if name == 'Neural Net':\n",
    "        response2 = get_BI(X_grid, BS_nn_models(gen, n_models=reps, n_samples=n_samples, extra_kwargs={'class_sep':1.7, 'scale':(v[i], v[i])}, hidden_channels=[30, 100, 50, 1], frequency=2, patience=25))\n",
    "    else:\n",
    "        response2 = get_BI(X_grid, BS_models(func, gen, reps=reps, n_samples=n_samples, scale=(v[i], v[i]), class_sep=1.7))\n",
    "    vmin = min(vmin, min(response2))\n",
    "    vmax = max(vmax, max(response2))\n",
    "    response2 = response2.reshape(xs.shape)\n",
    "\n",
    "    ax = axs[1][i]\n",
    "    #ax.set_title()\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response1, ax=ax, vmin=vmin, vmax=vmax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "\n",
    "    ax = axs[2][i]\n",
    "\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response2, ax=ax, vmin=vmin, vmax=vmax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "    i += 1\n",
    "\n",
    "\n",
    "plt.subplots_adjust(#left=0.1,\n",
    "                    bottom=.15,\n",
    "                    #right=0.9,\n",
    "                    top=.9,\n",
    "                    wspace=0.1,\n",
    "                    hspace=0.3)\n",
    "plt.savefig('plots/BI_bBI_variance_ds{}_{}_{}.png'.format(n_samples, gen, name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Bootstrap\n",
    "'''\n",
    "\n",
    "name = 'Gaussian Process'\n",
    "if name != 'Neural Net':\n",
    "    func = dict(zip(names, classifiers))[name]\n",
    "name_gen = 'Circular'\n",
    "gen = generator[name_gen]\n",
    "gridspec_kw={'height_ratios': [1, 1]}\n",
    "cbar_kws = dict(use_gridspec=False, location=\"bottom\")\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "bootstrap = [10, 30, 50, 100, 200]\n",
    "num = len(bootstrap)\n",
    "figure, axs = plt.subplots(3, num, figsize=(3*num, 10.5))\n",
    "reps = 64\n",
    "\n",
    "i = 0\n",
    "eps = 1\n",
    "n_ticks = 100\n",
    "\n",
    "\n",
    "dataset = get_dataset(1000, gen, n_samples=n_samples)\n",
    "ds = dataset\n",
    "(X_train, y_train), (X_test, y_test) = ds # X is the data point, y is the class label\n",
    "\n",
    "cm = plt.cm.RdBu # color map parameter\n",
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"]) # color for data points \n",
    "ax = axs[0][i] # position of subgraph\n",
    "ax.set_title('Data') # subgraph title\n",
    "# Plot the training points\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "ax.set_xlim(x_min, x_max) # axis range\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "for i in range(1,num):\n",
    "    ax = axs[0][i]\n",
    "    ax.axis('off')\n",
    "\n",
    "if name == \"Neural Net\":\n",
    "    sep_model = nn_models(gen, n_models=reps, n_samples=n_samples, hidden_channels=[30, 100, 50, 1], frequency=2, patience=20)\n",
    "else:\n",
    "    with threadpool_limits(limits=1):\n",
    "        sep_model = get_models(func, gen, reps=reps, n_samples=n_samples)\n",
    "\n",
    "# the area we draw is a bit larger than the range of data points\n",
    "x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "    \n",
    "    \n",
    "x = np.linspace(x_min, x_max, n_ticks)\n",
    "y = np.linspace(y_min, y_max, n_ticks)\n",
    "xs, ys = np.meshgrid(x, y)\n",
    "X_grid = np.c_[xs.ravel(), ys.ravel()]\n",
    "response1 = get_BI(X_grid, sep_model)\n",
    "vmin = min(response1)\n",
    "vmax = max(response1)\n",
    "response1 = response1.reshape(xs.shape)\n",
    "\n",
    "response2 = [None for j in range(num)]\n",
    "for i in range(num):\n",
    "    if name == 'Neural Net':\n",
    "        response2[i] = get_BI(X_grid, BS_nn_models(gen, n_models=bootstrap[i], n_samples=n_samples, hidden_channels=[30, 100, 50, 1], frequency=2, patience=25))\n",
    "    else:\n",
    "        with threadpool_limits(limits=1):\n",
    "            response2[i] = get_BI(X_grid, BS_models(func, gen, reps=bootstrap[i]))\n",
    "    vmin = min(vmin, min(response2[i]))\n",
    "    vmax = max(vmax, max(response2[i]))\n",
    "    response2[i] = response2[i].reshape(xs.shape)\n",
    "\n",
    "for i in range(num):\n",
    "    ax = axs[1][i]\n",
    "    ax.set_title('bootstrap={}'.format(bootstrap[i]))\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response1, ax=ax, vmin=vmin, vmax=vmax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "\n",
    "    ax = axs[2][i]\n",
    "\n",
    "    with np.errstate(all='ignore'):\n",
    "        sns.heatmap(response2[i], ax=ax, vmin=vmin, vmax=vmax, cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "\n",
    "\n",
    "plt.subplots_adjust(#left=0.1,\n",
    "                    bottom=.15,\n",
    "                    #right=0.9,\n",
    "                    top=.9,\n",
    "                    wspace=0.1,\n",
    "                    hspace=0.3)\n",
    "plt.savefig('plots/BI_bBI_bootstrap_ds{}_{}_{}.png'.format(n_samples, name_gen, name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppu.methods.bregman import get_BI, get_revised_BI\n",
    "\n",
    "\"\"\"\n",
    "Bootstrap\n",
    "\"\"\"\n",
    "n_samples = 10000\n",
    "\n",
    "name = \"Neural Net\"\n",
    "func = dict(zip(names, classifiers))[name]\n",
    "name_gen = \"Circular\"\n",
    "gen = generator[name_gen]\n",
    "gridspec_kw={\"height_ratios\": [1, 1]}\n",
    "cbar_kws = {\"use_gridspec\": False, \"location\": \"bottom\"}\n",
    "plt.rcParams.update({\"font.size\": 15})\n",
    "\n",
    "bootstrap = [75]\n",
    "num = len(bootstrap)\n",
    "figure, axs = plt.subplots(2, num+1, figsize=(3*num+3, 7))\n",
    "reps = 64\n",
    "\n",
    "i = 0\n",
    "eps = 1\n",
    "n_ticks = 100\n",
    "\n",
    "\n",
    "dataset = get_dataset(1000, gen, n_samples=n_samples)\n",
    "ds = dataset\n",
    "(X_train, y_train), (X_test, y_test) = ds # X is the data point, y is the class label\n",
    "\n",
    "x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "cm = plt.cm.RdBu # color map parameter\n",
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"]) # color for data points\n",
    "ax = axs[0][0] # position of subgraph\n",
    "ax.set_title(\"Data\") # subgraph title\n",
    "# Plot the training points\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "ax.set_xlim(x_min, x_max) # axis range\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "\n",
    "for i in range(num):\n",
    "    ax = axs[i+1][0]\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "with threadpool_limits(limits=4):\n",
    "    sep_model = get_models(func, gen, reps=reps, n_samples=n_samples)\n",
    "\n",
    "# the area we draw is a bit larger than the range of data points\n",
    "x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "\n",
    "\n",
    "x = np.linspace(x_min, x_max, n_ticks)\n",
    "y = np.linspace(y_min, y_max, n_ticks)\n",
    "xs, ys = np.meshgrid(x, y)\n",
    "X_grid = np.c_[xs.ravel(), ys.ravel()]\n",
    "# response1 = get_BI(X_grid, sep_model)\n",
    "response1 = get_revised_BI(X_grid, sep_model)\n",
    "vmin = min(response1)\n",
    "vmax = max(response1)\n",
    "response1 = response1.reshape(xs.shape)\n",
    "\n",
    "response2 = [None for j in range(num)]\n",
    "for i in range(num):\n",
    "    with threadpool_limits(limits=4):\n",
    "        #response2[i] = get_BI(X_grid, BS_models(func, gen, reps=bootstrap[i], n_samples=n_samples))\n",
    "        response2[i] = get_revised_BI(X_grid, BS_models(func, gen, reps=bootstrap[i], n_samples=n_samples))\n",
    "    vmin = min(vmin, min(response2[i]))  # noqa: PLW3301\n",
    "    vmax = max(vmax, max(response2[i]))  # noqa: PLW3301\n",
    "    response2[i] = response2[i].reshape(xs.shape)\n",
    "\n",
    "for i in range(num):\n",
    "    ax = axs[0][i+1]\n",
    "    ax.set_title(f\"bootstrap={bootstrap[i]}\")\n",
    "    with np.errstate(all=\"ignore\"):\n",
    "        sns.heatmap(response1, ax=ax, vmin=vmin, vmax=1., cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "\n",
    "    ax = axs[1][i+1]\n",
    "\n",
    "    with np.errstate(all=\"ignore\"):\n",
    "        sns.heatmap(response2[i], ax=ax, vmin=vmin, vmax=1., cbar_kws=cbar_kws).invert_yaxis()\n",
    "\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "\n",
    "\n",
    "plt.subplots_adjust(#left=0.1,\n",
    "                    bottom=.2,\n",
    "                    #right=0.9,\n",
    "                    top=.9,\n",
    "                    wspace=0.1,\n",
    "                    hspace=0.3)\n",
    "plt.savefig(f\"plots/BI_bBI_bootstrap_ds{n_samples}_{name_gen}_{name}.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "norm.cdf(np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = _check_boundary_response_method(clf, \"auto\")(X_grid)\n",
    "len(response.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 64\n",
    "n_samples = 10000\n",
    "gen_name = \"Circular\"\n",
    "gen = generator[gen_name]\n",
    "name = \"Neural Net\"\n",
    "clf = dict(zip(names, classifiers))[name]\n",
    "# Define the grid size\n",
    "grid_size = 70\n",
    "ticks_interval = int(grid_size / 8)\n",
    "\n",
    "\n",
    "figure, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "dataset = get_dataset(1000, gen, n_samples=n_samples)\n",
    "(X_train, y_train), (X_test, y_test) = dataset\n",
    "\n",
    "eps = 0.5\n",
    "x_min, x_max = X_train[:, 0].min() - eps, X_train[:, 0].max() + eps\n",
    "y_min, y_max = X_train[:, 1].min() - eps, X_train[:, 1].max() + eps\n",
    "\n",
    "cm = plt.cm.RdBu # color map parameter\n",
    "cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"]) # color for data points \n",
    "ax = axs[0][0] # position of subgraph\n",
    "ax.set_title(\"Data\") # subgraph title\n",
    "# Plot the training points\n",
    "ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors=\"k\")\n",
    "ax.set_xlim(x_min, x_max) # axis range\n",
    "ax.set_ylim(y_min, y_max)\n",
    "x_ticks = np.linspace(x_min, x_max, 6)\n",
    "y_ticks = np.linspace(y_min, y_max, 6)\n",
    "ax.set_xticks(x_ticks)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_xticklabels(f\"{tick:.1f}\" for tick in x_ticks)\n",
    "ax.set_yticklabels(f\"{tick:.1f}\" for tick in y_ticks)\n",
    "\n",
    "ax = axs[1][0]\n",
    "ax.axis('off')\n",
    "\n",
    "models = get_models(clf, gen, reps, n_samples=n_samples)\n",
    "\n",
    "# datasets = [get_dataset(i, gen, n_samples=n_samples) for i in range(reps)]\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = dataset\n",
    "x_min, x_max = X_train[:, 0].min(), X_train[:, 0].max()\n",
    "y_min, y_max = X_train[:, 1].min(), X_train[:, 1].max()\n",
    "\n",
    "feats = _check_boundary_response_method(models[0], \"auto\")(X_train)\n",
    "new_col = feats.reshape(-1, 1)\n",
    "data = np.hstack([X_train, new_col])\n",
    "\n",
    "for i in range(1, reps):\n",
    "    (X_train, y_train), (X_test, y_test) = get_dataset(1000, gen, n_samples=n_samples)\n",
    "    feats = _check_boundary_response_method(models[i], \"auto\")(X_train)\n",
    "    new_col = feats.reshape(-1, 1)\n",
    "    data_i = np.hstack([X_train, new_col])\n",
    "    data = np.vstack([data, data_i])\n",
    "\n",
    "    x_min, x_max = min(X_train[:, 0].min(), x_min), max(X_train[:, 0].max(), x_max)\n",
    "    y_min, y_max = min(X_train[:, 1].min(), y_min), max(X_train[:, 1].max(), y_max)\n",
    "\n",
    "\n",
    "x_min, x_max = x_min - eps, x_max + eps\n",
    "y_min, y_max = y_min - eps, y_max + eps\n",
    "\n",
    "x_range = x_max - x_min\n",
    "y_range = y_max - y_min\n",
    "\n",
    "aspect_ratio = x_range / y_range\n",
    "\n",
    "\n",
    "x_edges = np.linspace(x_min, x_max, grid_size+1)\n",
    "y_edges = np.linspace(y_min, y_max, grid_size+1)\n",
    "\n",
    "# Create arrays to store feature values in each grid cell\n",
    "feature_values = { (i, j): [] for i in range(grid_size) for j in range(grid_size) }\n",
    "\n",
    "# Assign each data point to a grid cell and collect feature values\n",
    "for (x, y, feature) in data:\n",
    "    x_idx = np.digitize(x, x_edges) - 1\n",
    "    y_idx = np.digitize(y, y_edges) - 1\n",
    "    feature_values[(x_idx, y_idx)].append(feature)\n",
    "\n",
    "# Compute the variance in feature values for each cell\n",
    "variance = np.zeros((grid_size, grid_size))\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        if feature_values[(i, j)]:\n",
    "            variance[i, j] = np.var(feature_values[(i, j)])\n",
    "        else:\n",
    "            variance[i, j] = 0.  # Marking cells with no data as NaN for clarity in visualization\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the heatmap of feature variance\n",
    "ax = axs[0][1]\n",
    "ax = sns.heatmap(variance, ax=ax, mask=np.isnan(variance), cmap=\"viridis\", cbar_kws={\"label\": \"Variance\"})\n",
    "ax.invert_yaxis()\n",
    "ax.set_aspect(aspect_ratio)\n",
    "\n",
    "\n",
    "ax.set_xticks(np.arange(len(x_edges)-1)[::ticks_interval] + 0.5)\n",
    "ax.set_yticks(np.arange(len(y_edges)-1)[::ticks_interval] + 0.5)\n",
    "x_labels = [(x_edges[i] + x_edges[i+1]) / 2 for i in range(len(x_edges)-1)]\n",
    "y_labels = [(y_edges[i] + y_edges[i+1]) / 2 for i in range(len(y_edges)-1)]\n",
    "ax.set_xticklabels(f\"{label:.2f}\" for index, label in enumerate(x_labels) if index % ticks_interval == 0)\n",
    "ax.set_yticklabels(f\"{label:.2f}\" for index, label in enumerate(y_labels) if index % ticks_interval == 0)\n",
    "# ax.set_title(\"Heatmap of Feature Variance in 2D Space\")\n",
    "\n",
    "\n",
    "bs_models = BS_models(clf, gen, reps, n_samples=n_samples)\n",
    "models\n",
    "# datasets = [get_dataset(i, gen, n_samples=n_samples) for i in range(reps)]\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = dataset\n",
    "x_min, x_max = X_train[:, 0].min(), X_train[:, 0].max()\n",
    "y_min, y_max = X_train[:, 1].min(), X_train[:, 1].max()\n",
    "\n",
    "feats = _check_boundary_response_method(bs_models[0], \"auto\")(X_train)\n",
    "new_col = feats.reshape(-1, 1)\n",
    "data1 = np.hstack([X_train, new_col])\n",
    "\n",
    "for i in range(1, reps):\n",
    "    (X_train, y_train), (X_test, y_test) = get_dataset(1000, gen, n_samples=n_samples)\n",
    "    feats = _check_boundary_response_method(bs_models[i], \"auto\")(X_train)\n",
    "    new_col = feats.reshape(-1, 1)\n",
    "    data_i = np.hstack([X_train, new_col])\n",
    "    data1 = np.vstack([data1, data_i])\n",
    "\n",
    "    x_min, x_max = min(X_train[:, 0].min(), x_min), max(X_train[:, 0].max(), x_max)\n",
    "    y_min, y_max = min(X_train[:, 1].min(), y_min), max(X_train[:, 1].max(), y_max)\n",
    "\n",
    "\n",
    "x_min, x_max = x_min - eps, x_max + eps\n",
    "y_min, y_max = y_min - eps, y_max + eps\n",
    "\n",
    "x_range = x_max - x_min\n",
    "y_range = y_max - y_min\n",
    "\n",
    "aspect_ratio = x_range / y_range\n",
    "\n",
    "\n",
    "x_edges = np.linspace(x_min, x_max, grid_size+1)\n",
    "y_edges = np.linspace(y_min, y_max, grid_size+1)\n",
    "\n",
    "# Create arrays to store feature values in each grid cell\n",
    "feature_values = { (i, j): [] for i in range(grid_size) for j in range(grid_size) }\n",
    "\n",
    "# Assign each data point to a grid cell and collect feature values\n",
    "for (x, y, feature) in data1:\n",
    "    x_idx = np.digitize(x, x_edges) - 1\n",
    "    y_idx = np.digitize(y, y_edges) - 1\n",
    "    feature_values[(x_idx, y_idx)].append(feature)\n",
    "\n",
    "# Compute the variance in feature values for each cell\n",
    "variance1 = np.zeros((grid_size, grid_size))\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        if feature_values[(i, j)]:\n",
    "            variance1[i, j] = np.var(feature_values[(i, j)])\n",
    "        else:\n",
    "            variance1[i, j] = 0.  # Marking cells with no data as NaN for clarity in visualization\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the heatmap of feature variance\n",
    "ax = axs[1][1]\n",
    "ax = sns.heatmap(variance1, ax=ax, mask=np.isnan(variance1), cmap=\"viridis\", cbar_kws={\"label\": \"Variance\"})\n",
    "ax.invert_yaxis()\n",
    "ax.set_aspect(aspect_ratio)\n",
    "\n",
    "ax.set_xticks(np.arange(len(x_edges)-1)[::ticks_interval] + 0.5)\n",
    "ax.set_yticks(np.arange(len(y_edges)-1)[::ticks_interval] + 0.5)\n",
    "x_labels = [(x_edges[i] + x_edges[i+1]) / 2 for i in range(len(x_edges)-1)]\n",
    "y_labels = [(y_edges[i] + y_edges[i+1]) / 2 for i in range(len(y_edges)-1)]\n",
    "ax.set_xticklabels(f\"{label:.2f}\" for index, label in enumerate(x_labels) if index % ticks_interval == 0)\n",
    "ax.set_yticklabels(f\"{label:.2f}\" for index, label in enumerate(y_labels) if index % ticks_interval == 0)\n",
    "# ax1.set_title(\"Heatmap of Feature Variance in 2D Space\")\n",
    "\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=.2,\n",
    "                    right=0.9,\n",
    "                    top=.9,\n",
    "                    wspace=0.2,\n",
    "                    hspace=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = np.array([[1,2,3],[2,3,4],[3,4,5]])\n",
    "bbb = np.array([[1,1,1],[2,2,2],[3,3,3]])\n",
    "for i,j in zip(aaa,bbb):\n",
    "    print(i.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_check_boundary_response_method(sep_model[0], \"auto\")(X_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ING",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
